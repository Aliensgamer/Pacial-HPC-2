# -*- coding: utf-8 -*-
"""Tercer Parcial HPC-2 - Dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DN_jVNH3rzIoDQ71bzsEJd5-JMpqa3Oq

Universidad Sergio Arboleda 

Fecha: 23/05/2022

Autor: Juan Jose Trujillo

Materia: HPC-2

Tema: Tercer Parcial HPC - 2

**1.- Se importan las bibliotecas necesarias**
"""

#Biblioteca para la manipulacion y analiticade datos
import pandas as pd
#Biblioteca para la presentacion de graficas, entre otros
import matplotlib.pyplot as plt
from matplotlib.figure import figaspect
#Biblioteca de visualización de datos, proporciona una interfaz de alto nivel para dibujar gráficos estadísticos atractivos e informativos
import seaborn as sns
#Bibliotecas para el aprendizaje automático
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline

"""**2.- Se carga el Dataset y se convierte en dataframe**"""

#Se importa el dataset asi mismo como lo entrega el profesor
dataset = pd.read_csv('/content/insuranceHPC.csv',sep=',')
dataset.head()

"""Se observan 6 columnas en el dataset, con fines que obtener mas informacion del dataset se lee el archivo adicional que tenia el dataset el cual nos dice que la variable a predecir seria "Charges", se necesita dejar la variable a predicir en la ultima columna entonces se procedera a modificar el dataset cambiando esa columna y moviendo las demas a la izquierda.

**3.- Se carga el Dataset editado y se verifica**
"""

#Se importa el dataset editado cambiando esas columnas
dataset = pd.read_csv('/content/insuranceHPC.csv',sep=',')
dataset.head()

"""Con el dataset ya de la forma se procede a realizar un analisis exploratorio

**4.- Se hace un Análisis exploratorio de datos(EDA) sobre el dataframe**
"""

dataset.columns

dataset['sex'].unique()

dataset['children'].unique()

"""Se revisan las columnas y analisamos que los intervalos de los datos que tiene el dataframe no sean nulos o distintos, analizadas todas las columnas parece estar normal."""

dataset.info()

"""El dataset no presenta valores desaparecidos, por lo tanto no hay hacer ningun tratamiento de datos"""

dataset.describe()

"""Se presenta la matriz de correlacion: Relacion entre las variables dependientes e independientes"""

MatCorrelacion = dataset.corr()
plt.figure(figsize=(12,6))
sns.heatmap(MatCorrelacion, annot=True, cmap='Spectral')
plt.title('Mapa de correlacion entre variables numericas del dataframe')
plt.show()

"""Con este mapa de calor, podemos observar las diferentes relaciones entre las variables, pero como queremos predecir "Charges" nos centraremos en en su relacion con las demas variables, encontramos que la variable mas significativa con la que tiene relacion es "smoker", esta relacion se encuentra negativa lo que signica que a valores negativos en "smoker" "charges" aumentara y viceversa, como los datos de "smoker" es 0 o 1, se entiende que cuando "smoker" es 0 el valor de "charges" aumentara"""

fig, axes = plt.subplots(1,3,figsize=(20,6))
axes[0].grid()
axes[1].grid()
axes[2].grid()
sns.histplot(dataset['age'], ax = axes[0], kde=True, color='r')
axes[0].set_title('Age: Distribucion')
sns.histplot(dataset['bmi'], ax = axes[1], kde=True, color='b')
axes[1].set_title('BMI: Distribucion')
sns.histplot(dataset['charges'], ax = axes[2], kde=True, color='r')
axes[2].set_title('Charges: Distribucion')
plt.show()

"""Se realiza la respectivo histogramas de cada variables (Seran 3 por que los histogramas son para variables continuas) en este podemos ver una distribucion bimodal en la edad, una distribucion normal en el indice de masa corporal y en cargos tenemos una distribucion derecho sesgado con 2 picos.

**5.- Crear un modelo en Python-Sklearn para Regresión Lineal usando la Normalización**
"""

X = dataset.drop(['charges'],axis=1)
y = dataset['charges']

"""Creamos las variables x y en las cuales x tendra el dataset menos la columna "charges", por otro lado y tendra solo la columna "charges", esto para representar las variables dependientes de las variables independientes"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

"""Para este modelo se divide el dataframe en 2 partes, la que vamos a entrenar y las de prueba, para este caso el tamaño de la parte de prueba sera el 20% del dataframe y el resto sera para entrenar al modelo"""

#A continuacion se hace un pipeline para entrenar el modelo, usando la normalizacion 
#(Similar a lo elaborado en c++ "Modelo artesanal de regresion lineal")
pipe = Pipeline([('scaler', StandardScaler()), ('LR', LinearRegression())])
pipe.fit(X_train, y_train)

"""Luego de dividir el dataframe tomamos el de entrenamiento y con ayuda de pipeline lo entrenamos usando la normalizacion (dividir cada predictor entre su desviación típica después de haber sido centrado, de esta forma, los datos pasan a tener una distribución normal).

**6.- Presentar el vector de coeficientes y punto de corte del Modelo RL en Sklearn**
"""

pipe['LR'].intercept_

pipe['LR'].coef_

"""Este serian nuestros coeficientes el cual representara el cambio medio en la variable de repuesta para la unidad de la variable predictora

**7.- Crear vectores de predicciones del modelo LR Sklearn (y_train_hat_sk, y_test_hat_sk)**
"""

#Variable de prediccion por sklearn 
y_hat_train_sk = pipe.predict(X_train)
y_hat_test_sk = pipe.predict(X_test)

"""Se crean los y_hat de entrenamiento y de prueba y se predicen con sus respectivas X de prueba y entrenamiento, esto con el fin de comparalos con el Modelo LR

**8.- Evaluar el modelo LR Sklearn para entrenamiento y prueba**
"""

fig, axes = plt.subplots(figsize=(12,6))
plt.scatter(y_test, y_hat_test_sk, c='b', label='Prueba')
plt.scatter(y_train, y_hat_train_sk, c='r', label='Entrenamiento')
axes.set_xlabel('Cargos Hospitalarios')
axes.set_ylabel('Prediccion cargos $\hat(y_i)$')
axes.set_title('Prediccion Cargos Hospitalarios $\hat(y_i)$')
plt.legend(loc=2)
plt.grid() 
plt.show()

"""Se aprecian las predicciones para y_hat de entrenamiento y prueba se ve como algunos de prueba estan bastante cerca de las de entrenamiento, cabe aclarar que prueba solo tiene 20% de todo el dataframe por tanto es una acercamiento sobre los de prueba bastante cercanos"""

pipe.score(X_train, y_train)

"""luego de eso obtenemos el puntaje de metrica que usa el pipeline .score, segun la metrica de rendimiento lo que hara es tomar cada valor de y resatado con cada valor de y_hat, se elevara a la 2 y se sumaran todos sus valores, ese seria nuestro numerador, para el denominador sera cara valor de y restado con el promedio y todo eso elevado a la 2 y tambien se sumaran los valores y luego se procedera a realizar "1-(numerador/denominador)".

**9.- Gráfico de la función de costo del modelo Cpp**
"""

costo = pd.read_csv('/content/VectorCosto.txt',sep=',', header=None)
fig, axes = plt.subplots(figsize=(12,6))
axes.plot(costo)
axes.set_xlabel('Epocas')
axes.set_ylabel(r'Costo $J(\theta)$')
axes.set_title('Costo para etrenamiento para RL del Wine, Modelo C++') 
plt.show()

"""Esta seria la funcion de costo la cual se vera como converje el valor al minimo que puede llegar esta funcion basa en el nuevo valor de theta.

**10.- gráfico comparativo de "Predicciones de entrenamiento modelo Sklearn vs predicciones de entrenamiento del modelo Cpp"**
"""

y_hat_train =pd.read_csv('/content/y_train_hat.txt')
fig, axes = plt.subplots(figsize=(12,6))
plt.scatter(y_train, y_hat_train, c='r', label='Prueba')
plt.scatter(y_train, y_hat_train_sk, c='green', label='Prueba')
axes.set_xlabel('Calidad del Wine')
axes.set_ylabel(r'Prediccion calidad $\hat(y_i)$')
axes.set_title('Prediccion Calidad del Wine $\hat(y_i)$')
plt.legend(loc=2)
plt.grid() 
plt.show()

"""En esta comparativa vemos como el codigo de C++ se acerco bastante a lo que queriamos lograr con este trabajo, logrando que casi no haya diferencia entre los 2 y_hat predichos.

**11.- gráfico comparativo de "Predicciones de prueba modelo Sklearn vs predicciones de prueba del modelo Cpp"**
"""

y_hat_test =pd.read_csv('/content/y_test_hat.txt', header=None)
fig, axes = plt.subplots(figsize=(12,6))
plt.scatter(y_test, y_hat_test, c='b', label='Prueba')
plt.scatter(y_test, y_hat_test_sk, c='r', label='Prueba')
axes.set_xlabel('Calidad del Wine')
axes.set_ylabel(r'Prediccion calidad $\hat(y_i)$')
axes.set_title('Prediccion Calidad del Wine $\hat(y_i)$')
plt.legend(loc=2)
plt.grid() 
plt.show()

"""En esta comparativa podemos ver que la diferecia entre los y_hat predichos se da una difrencia mayor en los cuadrantes 1 y 4, en lugar de los cuadrantes 2 y 3 se sienten bastante similiares en compraracion con los otros cuadrantes, sin duda podriamos decir que si le damos un poco mas del dataframe a las pruebas del Sklearn y C++ podriamos acercanos mas entre las predicciones."""